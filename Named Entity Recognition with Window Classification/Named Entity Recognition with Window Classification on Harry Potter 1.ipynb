{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gzip\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "from sklearn_crfsuite import metrics\n",
    "random.seed(1994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "if USE_CUDA:\n",
    "    gpus = [0]\n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex:eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "        \n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, word2index):\n",
    "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
    "    return Variable(LongTensor(idxs))\n",
    "\n",
    "\n",
    "def prepare_word(word, word2index):\n",
    "    return Variable(LongTensor([word2index[word]]) if word2index.get(word) is not None else LongTensor([word2index[\"<UNK>\"]]))\n",
    "\n",
    "def prepare_tag(tag, tag2index):\n",
    "    return Variable(LongTensor([tag2index[tag]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442745\n"
     ]
    }
   ],
   "source": [
    "def preprocess(sent):\n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "with open(\"Harry Potter txt/Harry Potter 1 - Sorcerer's Stone.txt\",'r', encoding = 'cp1252') as content_file:\n",
    "    all_text = content_file.read()\n",
    "    print(len(all_text))\n",
    "    doc = nlp(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the pretrained list of named entity is not used, generate the list manually\n",
    "data_list = []\n",
    "for j in range(0, len(sentences)):\n",
    "    entities = [(str(x), x.label_) for x in nlp(str(sentences[j])).ents]\n",
    "    my_list = []\n",
    "    for i in range(0,len(nlp(str(sentences[j])))):\n",
    "        if str(nlp(str(sentences[j][i]))) not in str(nlp(str(sentences[j])).ents):\n",
    "            my_list.append((str(nlp(str(sentences[j][i]))), 'O'))\n",
    "        else:\n",
    "            for k, v in entities:\n",
    "                if str(nlp(str(sentences[j][i]))) == k:\n",
    "                    my_list.append((k, v))\n",
    "    data_list.append(list(zip(*my_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the pretrained list of named entity is used, load the premade list\n",
    "\n",
    "def load(file_name):\n",
    "    # load the model\n",
    "    stream = gzip.open(file_name, \"rb\")\n",
    "    model = pickle.load(stream)\n",
    "    stream.close()\n",
    "    return model\n",
    "\n",
    "\n",
    "def save(file_name, model):\n",
    "    # save the model\n",
    "    stream = gzip.open(file_name, \"wb\")\n",
    "    pickle.dump(model, stream)\n",
    "    stream.close()\n",
    "data_list = load(\"data_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">For a <mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">second<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span></mark>, Mr. <mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">Dursley<span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span></mark> didn't realize what he had seen -- then he jerked his head around to look again.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = [x for x in doc.sents]\n",
    "displacy.render(nlp(str(sentences[20])), jupyter=True, style='ent', minify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('For', 'ADP', 'for'),\n",
       " ('second', 'NOUN', 'second'),\n",
       " ('Mr.', 'PROPN', 'mr.'),\n",
       " ('Dursley', 'PROPN', 'dursley'),\n",
       " (\"n't\", 'ADV', 'not'),\n",
       " ('realize', 'VERB', 'realize'),\n",
       " ('seen', 'VERB', 'see'),\n",
       " ('jerked', 'VERB', 'jerk'),\n",
       " ('head', 'NOUN', 'head'),\n",
       " ('look', 'VERB', 'look')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x.orth_,x.pos_, x.lemma_) for x in [y \n",
    "                                      for y\n",
    "                                      in nlp(str(sentences[20])) \n",
    "                                      if not y.is_stop and y.pos_ != 'PUNCT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('second', 'ORDINAL'), ('Dursley', 'PERSON')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(str(x), x.label_) for x in nlp(str(sentences[20])).ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PERSON', 3189), ('ORG', 950), ('GPE', 572)]\n"
     ]
    }
   ],
   "source": [
    "labels = [x.label_ for x in doc.ents]\n",
    "pprint(Counter(labels).most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Harry', 1278),\n",
      " ('Ron', 424),\n",
      " ('Hagrid', 239),\n",
      " ('Hermione', 202),\n",
      " ('Snape', 148)]\n"
     ]
    }
   ],
   "source": [
    "items = [x.text for x in doc.ents]\n",
    "pprint(Counter(items).most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {'<UNK>': 0, '<DUMMY>': 1}\n",
    "for word in vocab:\n",
    "    if word2index.get(word) is None:\n",
    "        word2index[word] = len(word2index)\n",
    "index2word = {v:k for k, v in word2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 2\n",
    "windows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = [x for x in data_list if x!= []]\n",
    "[i for i, x in enumerate(data_list) if x == []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in data_list:\n",
    "    dummy = ['<DUMMY>'] * WINDOW_SIZE\n",
    "    window = list(nltk.ngrams(dummy + list(sample[0]) + dummy,5))\n",
    "    windows.extend([[list(window[i]), sample[1][i]] for i in range(len(sample[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94163"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<DUMMY>', 'Mrs.', 'Dursley', 'was', 'thin'], 'PERSON']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(windows)\n",
    "\n",
    "train_data = windows[:int(len(windows) * 0.9)]\n",
    "test_data = windows[int(len(windows) * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, window_size, hidden_size, output_size):\n",
    "        super(WindowClassifier, self).__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.h1 = nn.Linear(embedding_size * (window_size * 2 + 1), hidden_size)\n",
    "        self.h2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.o = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self,inputs, is_training = False):\n",
    "        embeds = self.embed(inputs)\n",
    "        concated = embeds.view(-1, embeds.size(1)*embeds.size(2))\n",
    "        h_0 = self.relu(self.h1(concated))\n",
    "        if is_training:\n",
    "            h_0 = self.dropout(h_0)\n",
    "        h_1 = self.relu(self.h2(h_0))\n",
    "        if is_training:\n",
    "            h_1 = self.dropout(h_1)\n",
    "        out = self.softmax(self.o(h_1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, tags = list(zip(*train_data))\n",
    "tag2index = {v:k for k, v in enumerate(list(set(tags)))}\n",
    "index2tag = {k:v for v, k in tag2index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EMBEDDING_SIZE = 50 # x (WINDOW_SIZE*2+1) = 250\n",
    "HIDDEN_SIZE = 300\n",
    "EPOCH = 3\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WindowClassifier(len(word2index), EMBEDDING_SIZE, WINDOW_SIZE, HIDDEN_SIZE, len(tag2index))\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/3] mean_loss : 2.76\n",
      "[0/3] mean_loss : 0.25\n",
      "[0/3] mean_loss : 0.11\n",
      "[0/3] mean_loss : 0.09\n",
      "[0/3] mean_loss : 0.09\n",
      "[0/3] mean_loss : 0.08\n",
      "[0/3] mean_loss : 0.08\n",
      "[1/3] mean_loss : 0.10\n",
      "[1/3] mean_loss : 0.08\n",
      "[1/3] mean_loss : 0.07\n",
      "[1/3] mean_loss : 0.08\n",
      "[1/3] mean_loss : 0.07\n",
      "[1/3] mean_loss : 0.07\n",
      "[1/3] mean_loss : 0.07\n",
      "[2/3] mean_loss : 0.11\n",
      "[2/3] mean_loss : 0.07\n",
      "[2/3] mean_loss : 0.06\n",
      "[2/3] mean_loss : 0.07\n",
      "[2/3] mean_loss : 0.07\n",
      "[2/3] mean_loss : 0.06\n",
      "[2/3] mean_loss : 0.07\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    losses = []\n",
    "    for i,batch in enumerate(getBatch(BATCH_SIZE, train_data)):\n",
    "        x,y=list(zip(*batch))\n",
    "        inputs = torch.cat([prepare_sequence(sent, word2index).view(1, -1) for sent in x])\n",
    "        targets = torch.cat([prepare_tag(tag, tag2index) for tag in y])\n",
    "        model.zero_grad()\n",
    "        preds = model(inputs, is_training=True)\n",
    "    \n",
    "        loss = loss_function(preds, targets)\n",
    "        losses.append(loss.data.tolist())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(\"[%d/%d] mean_loss : %0.2f\" %(epoch, EPOCH, np.mean(losses)))\n",
    "            losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_f1_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.71689497716895\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for test in test_data:\n",
    "    x, y = test[0], test[1]\n",
    "    input_ = prepare_sequence(x, word2index).view(1, -1)\n",
    "\n",
    "    i = model(input_).max(1)[1]\n",
    "    pred = index2tag[i.data.tolist()[0]]\n",
    "    for_f1_score.append([pred, y])\n",
    "    if pred == y:\n",
    "        accuracy += 1\n",
    "\n",
    "print(accuracy/len(test_data) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High accuracy is due to large number of words with tag \"O\", need to look at other evaluation matrics. \n",
    "\n",
    "As an alternative, one can do random undersampling to reduce the number of instances of majority class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_test = list(zip(*for_f1_score))\n",
    "sorted_labels = sorted(\n",
    "    list(set(y_test) - {'O'}),\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        FAC      0.000     0.000     0.000         1\n",
      "   CARDINAL      0.773     0.872     0.819        39\n",
      "       DATE      0.000     0.000     0.000        11\n",
      "        LAW      0.000     0.000     0.000         1\n",
      "     PERSON      0.625     0.868     0.727       219\n",
      "       TIME      0.000     0.000     0.000        12\n",
      "        LOC      0.769     1.000     0.870        10\n",
      "       NORP      0.000     0.000     0.000         7\n",
      "        GPE      0.707     0.774     0.739        53\n",
      "    ORDINAL      0.923     0.923     0.923        13\n",
      "        ORG      0.648     0.639     0.644       147\n",
      "    PRODUCT      0.000     0.000     0.000         2\n",
      "\n",
      "avg / total      0.620     0.740     0.671       515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/DataAnalysis/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred = [[y] for y in y_pred] # this is because sklearn_crfsuite.metrics function flatten inputs\n",
    "y_test = [[y] for y in y_test]\n",
    "\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels = sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
